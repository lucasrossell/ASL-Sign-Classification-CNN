This project was created for the final project of a machine learning class at UCF. My partner and I set out to train an accurate 2D convolutional neural network that classifies images of American Sign Language symbols to their appropriate letters. The dataset consists of a pre made 80/20 train-test split in which each labelled 28x28 image has each of their 784 pixels' greyscale values. This dataset excludes the labels 9 and 25 which correspond to J and Z as these letters require gestures. Using keras library functions, we were able to achieve a very high accuracy and F1 score with our model. 
